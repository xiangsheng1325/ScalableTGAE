{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9008e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *\n",
    "from eval_utils import *\n",
    "from model_utils import *\n",
    "from models import *\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4579bbb2",
   "metadata": {},
   "source": [
    "# Load Temporal Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50e7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGameGraph(game, N, binary=True):\n",
    "\t# N is the number of players in the game\n",
    "\t# load csv data\n",
    "\t# unweighted and weighted networks can be loaded exactly the same way\n",
    "\t# below shows the loader for weighted networks\n",
    "\tif binary:\n",
    "\t\tdf_network = pd.read_csv(f'{src}/network{game}.csv', index_col = 0)\n",
    "\telse:\n",
    "\t\tdf_network = pd.read_csv(f'{src}/network{game}_weighted.csv', index_col = 0)\n",
    "\n",
    "\n",
    "\t# T is number of timestamps (10 frames)\n",
    "\tT = len(df_network)\n",
    "\t# load VFOA network to T x N x (N+1) array\n",
    "\t# vfoa[t, n, i] is the probability of player n+1 looking at object i at time t\n",
    "\t# i: 0 - laptop, 1 - player 1, 2 - player 2, ..., N - player N\n",
    "\tvfoa = np.reshape(df_network.values, (T,N,N+1))\n",
    "\n",
    "\t# print information\n",
    "\tprint(f'network id:{game}\\t length(x 1/3 second): {T}\\t num of players: {N}')\n",
    "\treturn vfoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0150374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network id:0\t length(x 1/3 second): 7323\t num of players: 7\n"
     ]
    }
   ],
   "source": [
    "src = './data' # root dir of data\n",
    "meta = pd.read_csv('./data/network_list.csv')\n",
    "gdata = []\n",
    "for _, row in meta.iterrows():\n",
    "\tgdata.append(loadGameGraph(row['NETWORK'], row['NUMBER_OF_PARTICIPANTS']))\n",
    "\tbreak\n",
    "# T x N x (N+1)\n",
    "myg = gdata[0]\n",
    "# 把看laptop变换到对角线对应值\n",
    "newg = np.stack([x[:, 1:]+np.diag(x[:, 0]) for x in myg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f5b51b",
   "metadata": {},
   "source": [
    "# Train Temporal Graph AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "647d5f39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name:  ./game_network_0.npy\n",
      "'TEMPORAL' Approach\n",
      "newg.shape[0]:  7323\n",
      "_A_obs.shape[0]:  51261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuchenhao/anaconda3/envs/graph_generation/lib/python3.6/site-packages/scipy/sparse/_index.py:124: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   5/400 Loss: 1.92223 Edge-Overlap: 0.594 Total-Time: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuchenhao/anaconda3/envs/graph_generation/lib/python3.6/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "/home/xuchenhao/anaconda3/envs/graph_generation/lib/python3.6/site-packages/scipy/sparse/_index.py:124: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "/home/xuchenhao/anaconda3/envs/graph_generation/lib/python3.6/site-packages/powerlaw.py:1151: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.alpha = 1 + (self.n / sum(log(data/self.xmin)))\n",
      "/home/xuchenhao/anaconda3/envs/graph_generation/lib/python3.6/site-packages/networkx/algorithms/assortativity/correlation.py:287: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (xy * (M - ab)).sum() / numpy.sqrt(vara * varb)\n",
      "/home/xuchenhao/graph_generation/meeting/220114/model_utils.py:61: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  v += np.abs(stats_A[i][k] - stats_B[i][k]) / stats_A[i][k]\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "EDGE_OVERLAP_LIMIT = {\n",
    "    'CORA-ML' : 0.7, \n",
    "    'Citeseer' : 0.8,\n",
    "    'PolBlogs': 0.41,\n",
    "    'RT-GOP': 0.7\n",
    "}\n",
    "MAX_STEPS = 400\n",
    "\n",
    "\n",
    "def random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "class parse_arguments(object):\n",
    "    def __init__(self):\n",
    "        self.data_path = \"./game_network_0.npy\"\n",
    "        self.data_name = 'game_0'\n",
    "        self.statistics_step = 10\n",
    "        self.number_of_samples = 5\n",
    "        self.H = 9\n",
    "        self.g_type = 'temporal'\n",
    "        self.lr = 0.05\n",
    "        self.weight_decay = 1e-6\n",
    "        self.graphic_mode = 'overlap'\n",
    "        self.fig_path = None\n",
    "        #self.fig_path = 'game_network.pdf'\n",
    "        self.table_path = 'logs/game.csv'\n",
    "        self.eo_limit = 0.5\n",
    "        self.criterion = 'eo'\n",
    "        self.seed = 42\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # 导入邻接矩阵\n",
    "    _A_obs, _X_obs, _z_obs = load_npy(args.data_path)\n",
    "\n",
    "    # 将输入图变为无向、对称阵\n",
    "    temp_A_obs = _A_obs.toarray().reshape(-1, _A_obs.shape[1], _A_obs.shape[1])\n",
    "    for i in range(len(temp_A_obs)):\n",
    "        temp_A_obs[i] = temp_A_obs[i] + temp_A_obs[i].T + np.eye(temp_A_obs[i].shape[0])\n",
    "    _A_obs = sp.csr_matrix(temp_A_obs.reshape(_A_obs.shape[0], _A_obs.shape[1]))\n",
    "    \n",
    "    #_A_obs = _A_obs + _A_obs.T\n",
    "    _A_obs[_A_obs > 1] = 1\n",
    "    #_A_obs = _A_obs - sp.eye(_A_obs.shape[0], _A_obs.shape[0])\n",
    "    _A_obs[_A_obs < 0] = 0\n",
    "    #lcc = largest_connected_components(_A_obs)\n",
    "    #_A_obs = _A_obs[lcc,:][:,lcc]\n",
    "    _N = _A_obs.shape[0]\n",
    "\n",
    "    # 验证边的比例\n",
    "    val_share = 0.05\n",
    "    # 测试边的比例\n",
    "    test_share = 0.1\n",
    "    seed = 42\n",
    "\n",
    "    # 将邻接矩阵分割为训练、验证、测试集\n",
    "    train_ones, val_ones, val_zeros, test_ones, test_zeros = train_val_test_split_adjacency(_A_obs, \n",
    "                                                                                            val_share, \n",
    "                                                                                            test_share, \n",
    "                                                                                            seed,\n",
    "                                                                                            every_node=False,\n",
    "                                                                                            undirected=False, \n",
    "                                                                                            connected=False, \n",
    "                                                                                            asserts=False)\n",
    "    # 训练集转为稀疏矩阵\n",
    "    train_graph = sp.coo_matrix((np.ones(len(train_ones)),(train_ones[:,0], train_ones[:,1]))).tocsr()\n",
    "    # assert (train_graph.toarray() == train_graph.toarray().T).all()\n",
    "\n",
    "    # 边重叠限制\n",
    "    if args.eo_limit is not None:\n",
    "        edge_overlap_limit = args.eo_limit \n",
    "    elif args.data_name in EDGE_OVERLAP_LIMIT.keys():\n",
    "        edge_overlap_limit = EDGE_OVERLAP_LIMIT[args.data_name]\n",
    "    else:\n",
    "        edge_overlap_limit = 0.6\n",
    "\n",
    "    training_stat = dict()\n",
    "    \n",
    "    # 图类型\n",
    "    if args.g_type != 'all':\n",
    "        training_stat[args.g_type] = list()\n",
    "    else:\n",
    "        training_stat = {i: list() for i in ['cell', 'fc', 'svd']}\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    # 对所有模型\n",
    "    for model_name in list(training_stat.keys()):\n",
    "        print(f\"'{model_name.upper()}' Approach\")\n",
    "        # 优化器参数\n",
    "        optimizer_args = {'lr': args.lr, 'weight_decay': args.weight_decay}\n",
    "        if model_name == 'fc':\n",
    "            optimizer_args['weight_decay'] = 1e-4\n",
    "        if args.criterion == 'eo':\n",
    "            callbacks = [EdgeOverlapCriterion(invoke_every=5, \n",
    "                                            edge_overlap_limit=edge_overlap_limit)]\n",
    "        elif args.criterion == 'val':\n",
    "            callbacks = [LinkPredictionCriterion(invoke_every=2,\n",
    "                                                val_ones=val_ones,\n",
    "                                                val_zeros=val_zeros,\n",
    "                                                max_patience=5)]\n",
    "\n",
    "        if args.fig_path is not None:\n",
    "            invoke_every = args.statistics_step \n",
    "        else:\n",
    "            invoke_every = MAX_STEPS + 1\n",
    "        stat_collector = StatisticCollector(invoke_every, _A_obs, test_ones, test_zeros, graphic_mode=args.graphic_mode, n_samples=args.number_of_samples)\n",
    "        callbacks.append(stat_collector)\n",
    "        \n",
    "        print(\"newg.shape[0]: \", newg.shape[0])\n",
    "        print(\"_A_obs.shape[0]: \", _A_obs.shape[0])\n",
    "\n",
    "        model = Cell(A=train_graph, \n",
    "                    H=args.H, \n",
    "                    T=newg.shape[0],\n",
    "                    g_type=model_name, \n",
    "                    callbacks=callbacks,\n",
    "                    device=DEVICE)\n",
    "\n",
    "        model.train(steps=MAX_STEPS,\n",
    "                optimizer_fn=torch.optim.Adam,\n",
    "                optimizer_args=optimizer_args)\n",
    "\n",
    "        stat_collector.invoke(None, model)\n",
    "        training_stat[model_name] = stat_collector.training_stat\n",
    "        stats = training_stat[model_name][-1]['stats']\n",
    "        stat_df = pd.DataFrame({k: [s[k] for s in stats] for k in stats[0].keys()})\n",
    "        stat_df = stat_df.mean()\n",
    "        df[model_name] = stat_df.T\n",
    "\n",
    "    #original_stat = compute_graph_statistics(_A_obs)\n",
    "    #df[args.data_name] = list(original_stat.values()) + [1, 1, 1]\n",
    "    if args.table_path is not None:\n",
    "        df.to_csv(args.table_path)\n",
    "\n",
    "    if args.fig_path is not None:\n",
    "        fig, axs = plt.subplots(3, 3, figsize=(15,9))\n",
    "        fig.suptitle(args.data_name, fontsize=18)\n",
    "        for stat_id, (stat_name, stat) in enumerate(\n",
    "            list(zip(['Max.Degree','Assortativity', 'Power law exp.', 'Rel. edge distr. entr', \n",
    "            'Clustering coeff.', 'Gini coeff.','Wedge count', 'Triangle count', 'Square count'], \n",
    "            ['d_max', 'assortativity', 'power_law_exp', 'rel_edge_distr_entropy', 'clustering_coefficient', 'gini',\n",
    "            'wedge_count', 'triangle_count', 'square_count']))):\n",
    "\n",
    "            axs[stat_id // 3, stat_id % 3].set_ylabel(stat_name, fontsize=18)\n",
    "            if args.graphic_mode == 'overlap':\n",
    "                axs[stat_id // 3, stat_id % 3].set_xlabel('Edge overlap (in %)', fontsize=13)\n",
    "            else:\n",
    "                axs[stat_id // 3, stat_id % 3].set_xlabel('Iterations', fontsize=13)\n",
    "            axs[stat_id // 3, stat_id % 3].axhline(y=original_stat[stat], color='g', linestyle='--', label='target')\n",
    "            for model_name, model_statistic in training_stat.items():\n",
    "                if args.graphic_mode == 'overlap':\n",
    "                    xs = [100 * i['overlap'] for i in model_statistic]\n",
    "                else:\n",
    "                    xs = [i['iteration'] for i in model_statistic]\n",
    "                    \n",
    "                axs[stat_id // 3, stat_id % 3].errorbar(xs, \n",
    "                                                        [np.mean([j[stat] for j in i['stats']]) for i in model_statistic],\n",
    "                                                        [np.std([j[stat] for j in i['stats']]) for i in model_statistic],\n",
    "                                                        ls='none',\n",
    "                                                        fmt='.',\n",
    "                                                        label=model_name\n",
    "                                                        )\n",
    "\n",
    "        axLine, axLabel = axs[stat_id // 3, stat_id % 3].get_legend_handles_labels()\n",
    "        fig.legend(axLine, axLabel, loc = 'center right', fontsize=15)\n",
    "        fig.tight_layout()\n",
    "        if args.fig_path is not None:\n",
    "            plt.savefig(args.fig_path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "args = parse_arguments()\n",
    "if args.seed is not None:\n",
    "    random_seed(args.seed)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39061637",
   "metadata": {},
   "source": [
    "# 已经完成的内容\n",
    "1. 写完工具脚本\n",
    "2. 写完模型训练\n",
    "3. 定义了最简单的temporal graph autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c97622",
   "metadata": {},
   "source": [
    "# 接下来要做的事\n",
    "1. 把现有的评估指标跑通（taggen里面最重要的实验里用到的指标）\n",
    "2. 在相同的数据集、相同的评估指标上比较现有模型和taggen的性能。\n",
    "3. 实现并训练新的temporal graph encoder，在1的基础上刷评估指标\n",
    "4. 设计完整的实验（参考taggen论文，可能加入一些新的实验，一周后再讨论）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8e336",
   "metadata": {},
   "source": [
    "# 时间安排\n",
    "1. 1月13号-1月16号完成\n",
    "2. 1月17号-1月18号完成\n",
    "3. 1月19号-1月23号完成\n",
    "4. 新实验和论文同时做 1月24号-1月30号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e6be40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a49f69ae36c9ae2b1d0d95cf93f112924f7cd21d5450d5668cfa55d825aa0a6"
  },
  "kernelspec": {
   "display_name": "graphgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
